# CS109 - Data Science
### Summer 2018
----

## Final Project: Twitter Bot Detection
Project: https://github.com/eumarassis/Harvard-s109-TwitterBotDetection

In a team of four, we assembled and trained a variety of classification algorithms (KNN, LogReg, AdaBoost, Random Forest, etc) on a large set of prelabeled twitter data (bots, non-bots). The Random Forest classifier achieved 80% accuracy on the testing data. 

----

## Problem Sets


### Pset 1

#### Data Mining/Scraping 

This assignment utilized request/get libraries, and later on beatifulsoup, to scrape IMDb data. 

### Pset 2

#### Linear and k-NN Regression

This assignment explored k-nearest neighbor and linear regression methods for predicting quantitative variables. Regression models were built to predict the number of taxi pickups in NYC at any given time of the day. This project could be used by taxicab drivers to predict their earnings, and city officials to predict traffic.


### Pset 3

#### EDA, Multiple Linear Regression, Subset Selection, Polynomial Regression

This assignment explored another group of prediction methodologies to forecast bike sharing usage.



### Pset 4

#### Feature Selection via Regularization (Lasso and Ridge Regression) and Cross Validation

This assigment continued to explore the bike sharing data. Feature selection techniques were explored, begining with bootstrapping a multiple linear regression model. Further in the assignment we explored regularization and penalization methods. Towards the end of the assignment we developed cross validation algorithms to evaluate our models.


### Pset 5

#### Logistic Regression, High Dimensionality and PCA, LDA/QDA

This assignment explored genomics data using classification models. 


### Pset 6

#### Ensemble Methods, and Neural Networks

This assigment explored bagging techniques for classification models, namely decision trees and randm forests, on Higgs Boson data. Boostong models (AdaBoost) on classifiers to improve on the decision tree's accuracies. Later an ensemble method is built on the results of 5 model's prediction (ada, rd, log, qda, knn), supplemented with training data.  Lastly, a sequential neural network built on keras is used to predict simulated data (a sinewave). 

